# üß† One Brain, Two Heads: A DeBERTa-Based Multi-Task Framework for Crime Detection on Twitter (X)

## üìå Overview

---

Social media platforms such as **Twitter (now X)** generate massive volumes of real-time textual data related to crime, conflict, and public safety. However, tweets are often **short, noisy, and context-dependent**, making automated crime detection a challenging research problem.

This project introduces a **unified multi-task transformer framework** called:

---

> **üß† One Brain, Two Heads**

The architecture leverages a **shared DeBERTa-v3-base encoder** with two parallel task-specific heads to simultaneously:

‚úÖ Detect crime-related tweets (Binary Classification)
‚úÖ Categorize crime into fine-grained sub-types (Multi-Class Classification)

Unlike many prior works, this approach is **fully text-only**, scalable, and does not rely on metadata or multimodal inputs.

---

## üöÄ Key Contributions

‚úîÔ∏è Novel **multi-task architecture** reducing error propagation
‚úîÔ∏è Hybrid dataset construction with **zero-shot labeling + human verification**
‚úîÔ∏è Weighted composite loss to address **class imbalance**
‚úîÔ∏è Transformer-based contextual modeling for noisy social media text
‚úîÔ∏è Achieved strong performance without auxiliary metadata

---

## üèóÔ∏è Architecture: One Brain, Two Heads

**Shared Encoder ("Brain"):**

* DeBERTa-v3-base
* 12 transformer layers
* Hidden size: 768

**Parallel Expert Heads:**

### üîπ Head A ‚Äî Binary Detection

Predicts whether a tweet contains criminal intent.

* Dense Layer (768 ‚Üí 1)
* Sigmoid activation
* Optimized using **Binary Cross-Entropy Loss**

---

### üîπ Head B ‚Äî Multi-Class Categorization

Identifies the specific crime type.

* Dense Layer (768 ‚Üí 6)
* Softmax activation
* Optimized using **Focal Loss** to handle class imbalance

---

## ‚öôÔ∏è Composite Loss Function

```
L_total = Œª1 * L_BCE + Œª2 * L_Focal
```

Where:

| Parameter | Value | Purpose                                 |
| --------- | ----- | --------------------------------------- |
| Œª1        | 0.3   | Prevents majority class dominance       |
| Œª2        | 0.7   | Prioritizes fine-grained classification |
| Œ≥         | 2.0   | Focuses training on hard examples       |

---

## üìä Dataset Construction Pipeline

A hybrid annotation framework was designed to ensure both **scalability and label quality**.

### Data Sources

* Public Tweets to Police India
* Crime Tweets Dataset
* How ISIS Uses Twitter
* Sexual Violence Dataset

### Preprocessing Steps

1. Data cleaning (URLs, emojis, duplicates removed)
2. Zero-shot labeling using **BART-large-MNLI**
3. Manual verification for low-confidence samples
4. SBERT embeddings + K-Means clustering for crime sub-types

---

## üßæ Crime Categories

* Armed Combat & Weaponry
* Counter-Terrorism & Arrests
* Crimes Against Civilians
* Extremist Propaganda
* Sexual Violence

---

## üß™ Experimental Setup

| Parameter           | Value                  |
| ------------------- | ---------------------- |
| Framework           | PyTorch + Hugging Face |
| Optimizer           | AdamW                  |
| Learning Rate       | 1e-5                   |
| Batch Size          | 16                     |
| Epochs              | 6                      |
| Scheduler           | Cosine with warm-up    |
| Max Sequence Length | 128                    |
| Dropout             | 0.3                    |

---

## üìà Results

| Model             | Parameters | Binary Accuracy | Multi-Class Accuracy |
| ----------------- | ---------- | --------------- | -------------------- |
| BERTweet-Base     | 135M       | 85.82%          | 78.90%               |
| BERTweet-Large    | 355M       | 86.79%          | 80.04%               |
| ‚≠ê DeBERTa-v3-Base | 184M       | **87.30%**      | **80.08%**           |

üëâ DeBERTa outperformed larger models, highlighting the strength of **disentangled attention** for nuanced crime-context understanding.

---

## üîé Error Analysis

The model showed:

‚úÖ Near-perfect sensitivity for **Sexual Violence**
‚úÖ Strong minority-class handling via Focal Loss

Primary confusion occurred between:

> Counter-Terrorism vs. Extremist Propaganda

‚Äî largely due to semantic overlap.

---

## üíª Installation

```bash
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO
pip install -r requirements.txt
```

---

## ‚ñ∂Ô∏è Usage

Example training workflow:

```bash
python train.py
```

Example inference:

```bash
python predict.py --text "Police arrested the suspect after the attack."
```

---

## ‚ö†Ô∏è Note on Models & Dataset

Large trained models and datasets are **not included** in this repository due to GitHub size limits.

üëâ (Add Google Drive / HuggingFace link here)

---

## üîÆ Future Work

* Real-time streaming crime detection
* Multilingual transformer support
* Explainable AI for law enforcement
* Multimodal fusion with images/video

---

## üéì Research Impact

This work demonstrates that:

> **Text alone can support scalable, efficient, and reliable real-time crime monitoring.**

The proposed architecture provides a practical foundation for automated public-safety intelligence systems.

---

## ü§ù Contributions

Contributions, issues, and feature requests are welcome!

If you find this project useful, consider giving it a ‚≠ê on GitHub.
